{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Twitter Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this homework, we are going to play with Twitter data.\n",
    "\n",
    "The data is represented as rows of of [JSON](https://en.wikipedia.org/wiki/JSON#Example) strings.\n",
    "It consists of tweets, messages, and a small amount of broken data (cannot be parsed as JSON).\n",
    "\n",
    "For this homework, we will only focus on tweets and ignore all other messages.\n",
    "\n",
    "**Search for `Tasks` to find out what you need to implement. You should only replace**\n",
    "\n",
    "```\n",
    "### \n",
    "### YOUR CODE HERE\n",
    "###\n",
    "```\n",
    "\n",
    "**with your code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Data overview \n",
    "\n",
    "### Tweets\n",
    "\n",
    "A tweet consists of many data fields. You can learn all about them in the Twitter API doc. We are going to briefly introduce only the data fields that will be used in this homework.\n",
    "\n",
    "* `created_at`: Posted time of this tweet (time zone is included)\n",
    "* `id_str`: Tweet ID - we recommend using `id_str` over using `id` as Tweet IDs, becauase `id` is an integer and may bring some overflow problems.\n",
    "* `text`: Tweet content\n",
    "* `user`: A JSON object for information about the author of the tweet\n",
    "    * `id_str`: User ID\n",
    "    * `name`: User name (may contain spaces)\n",
    "    * `screen_name`: User screen name (no spaces)\n",
    "* `retweeted_status`: A JSON object for information about the retweeted tweet (i.e. this tweet is not original but retweeteed some other tweet)\n",
    "    * All data fields of a tweet except `retweeted_status`\n",
    "* `entities`: A JSON object for all entities in this tweet\n",
    "    * `hashtags`: An array for all the hashtags that are mentioned in this tweet\n",
    "    * `urls`: An array for all the URLs that are mentioned in this tweet\n",
    "\n",
    "\n",
    "### Users partition\n",
    "\n",
    "Besides the original tweets, we will provide you with a Pickle file, which contains a partition over 452,743 Twitter users. It contains a Python dictionary `{user_id: partition_id}`. The users are partitioned into 7 groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Grading\n",
    "\n",
    "### Scale on datasets with different sizes\n",
    "\n",
    "Your implementation for this assignment will be graded on both correctness and runtimes. You will have a 0 score if your results do not match the expected values for each data set. If your results are correct, your score is dependent on the runtime.\n",
    "\n",
    "On Vocareum, we provide three different input sizes to test your program: 10 MB, 1 GB, and 10 GB. For any run, we will only be using one of these 3 datasets. **You can switch between different parts on Vocareum to test on different data files.** When you submit, you will be graded only for the part you have selected.\n",
    "\n",
    "Although there are 3 different parts, **we will only provide the standard answers for the 10 MB part**, which are given as\n",
    "\n",
    "> ---\n",
    "> **It should print**\n",
    "\n",
    "in the write-ups below. If you follow the instructions below to develop your solution for the 10 MB part, it should also produce the correct results for other parts. \n",
    "\n",
    "**Don't change any print funcitons that we provided in the starter code.** In the grading process, the correctness of your solution is checked by comparing the content of the variables, NOT the printed outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Running locally and on clusters\n",
    "\n",
    "The Spark application will run locally with limited resources when you develop your program in the Jupyter notebook. However, when you submit your solution for grading, your implementation will be first converted to a python script and then submitted to a Spark cluster with much more resources for correctness and runtime evaluations.\n",
    " \n",
    "Due to resource constraints, you cannot use the Spark cluster while developing your solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:35.797672Z",
     "start_time": "2023-02-12T15:11:35.760916Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your program will run locally\n"
     ]
    }
   ],
   "source": [
    "# `ON_EMR` indicates whether your program is running locally or on the clusters.\n",
    "# We assume it will run locally if this script is in the interactive mode (jupyter notebook) \n",
    "# and run on clusters if it is invoked by a shell command.\n",
    "# DO NOT CHANGE THE VALUE OF `ON_EMR` in your program.\n",
    "\n",
    "import sys\n",
    "\n",
    "ON_EMR = not hasattr(sys, 'ps1')\n",
    "print('Your program will run {}'.format(['locally', 'on clusters'][ON_EMR]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### OutputLogger\n",
    "\n",
    "`OutputLogger` object `my_output` is defined to store the results of your program. We have provided function calls to `my_output.append()` method for storing the results in all necessary places. In the last cell of this file, we write the content of `my_output` to a pickle file which the grader will read in and use for grading.\n",
    "\n",
    "**We have already appended all necessary variables to `my_output` in the starter code. Thus, don't change anything related to `my_output` or add more results to `my_output`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:35.974792Z",
     "start_time": "2023-02-12T15:11:35.802555Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "import pickle\n",
    "\n",
    "class OutputLogger:\n",
    "    def __init__(self):\n",
    "        self.ans = {}\n",
    "\n",
    "    def append(self, key, value):\n",
    "        self.ans[key] = value\n",
    "\n",
    "    def write_to_disk(self):\n",
    "        filepath = os.path.expanduser(\"answer.pickle\")\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.ans, f)\n",
    "        \n",
    "        # If ON_EMR, copy answer.pickle from the driver to HDFS\n",
    "        if ON_EMR:\n",
    "            proc = subprocess.Popen([\"/usr/local/hadoop/hadoop-2.7.4/bin/hadoop\", \"fs\", \"-copyFromLocal\", filepath, \"/user/spark/answer.pickle\"])\n",
    "            proc.wait()\n",
    "            os.remove(filepath)\n",
    "\n",
    "my_output = OutputLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Measuring runtime\n",
    "\n",
    "This is a useful cell for debugging. You can use `save_time(key)` at different parts of your code for checking the amount of time a segment takes. We have added it to the different parts of the starter code. You are free to use it where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:36.071394Z",
     "start_time": "2023-02-12T15:11:35.989451Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "\n",
    "timer = {}\n",
    "def save_time(key):\n",
    "    '''\n",
    "    Calling save_time with 'key' the first time will record the current time for 'key'.\n",
    "    Calling save_time with 'key' the second time will record the time (hours:minutes:seconds) \n",
    "    it takes from the first calling to the second calling. All results will be saved\n",
    "    in timer dict.\n",
    "    Calling save_time with 'key' the third time will overwrite existing data.\n",
    "    \n",
    "    Args:\n",
    "        key: an identifier for this time.\n",
    "    '''\n",
    "    \n",
    "    if key in timer: \n",
    "        if type(timer[key]) == str:\n",
    "            timer[key] = time()\n",
    "        else:\n",
    "            timer[key] = str(datetime.timedelta(seconds=round(time() - timer[key])))\n",
    "    else:\n",
    "        timer[key] = time()\n",
    "                \n",
    "save_time('total time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part 0: Load data to an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:42.364706Z",
     "start_time": "2023-02-12T15:11:36.077971Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "save_time(\"set up sc\")\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "save_time(\"set up sc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Read text file\n",
    "\n",
    "For local testing, the data files are in a public directory where you can read the file directly. The path to the data file is hard-coded in the `file_path` variable as part of the starter code.\n",
    "\n",
    "For submission, we will create this file on our server for testing with the appropriate file path. You should not worry about which file system (i.e. local file system or HDFS) Spark will read data from since the `file_path` variable we provide below will always contain the correct path to the data file.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Make RDD from the data in the file given by `file_path`.\n",
    "2. Mark the RDD to be cached (so in the next operation data will be loaded in memory)\n",
    "3. Count the number of elements in the RDD and store the result in `num_tweets`.\n",
    "\n",
    "**Hint:** use [`sc.textFile()`](https://spark.apache.org/docs/2.3.0/api/python/pyspark.html#pyspark.SparkContext.textFile) to read the text file into an RDD.\n",
    "\n",
    "***\n",
    "\n",
    "**It should print**\n",
    "```\n",
    "Number of elements: 2150\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.102837Z",
     "start_time": "2023-02-12T15:11:42.370420Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 2150\n"
     ]
    }
   ],
   "source": [
    "save_time(\"read data\")\n",
    "\n",
    "if ON_EMR:\n",
    "    file_path = '/user/spark/twitter/twitter.txt'\n",
    "else:\n",
    "    file_path = './resource/asnlib/publicdata/twitter.txt'\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "rdd = sc.textFile(file_path)\n",
    "rdd = rdd.cache()\n",
    "num_tweets = rdd.count()\n",
    "\n",
    "my_output.append(\"num-tweets\", num_tweets)\n",
    "print('Number of elements:', num_tweets)\n",
    "save_time(\"read data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.337351Z",
     "start_time": "2023-02-12T15:11:47.108236Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"created_at\":\"Tue Feb 23 17:43:33 +0000 2016\",\"id\":702187050557001728,\"id_str\":\"702187050557001728\",\"text\":\"RT @IngrahamAngle: GOP in Full Panic Mode Over Trump: Party scrambles to take down mogul by whatever means necessary https:\\\\/\\\\/t.co\\\\/flz6PNYM6\\\\u2026\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/twitter.com\\\\/download\\\\/android\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eTwitter for Android\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":3324919772,\"id_str\":\"3324919772\",\"name\":\"Connie Baughman\",\"screen_name\":\"baughman_cb\",\"location\":null,\"url\":null,\"description\":null,\"protected\":false,\"verified\":false,\"followers_count\":289,\"friends_count\":36,\"listed_count\":40,\"favourites_count\":13064,\"statuses_count\":22004,\"created_at\":\"Sat Aug 22 20:08:12 +0000 2015\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_tile\":false,\"profile_link_color\":\"0084B4\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/665234097082511361\\\\/tmtnyjtC_normal.jpg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/665234097082511361\\\\/tmtnyjtC_normal.jpg\",\"default_profile\":true,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"retweeted_status\":{\"created_at\":\"Tue Feb 23 16:15:37 +0000 2016\",\"id\":702164920578789377,\"id_str\":\"702164920578789377\",\"text\":\"GOP in Full Panic Mode Over Trump: Party scrambles to take down mogul by whatever means necessary https:\\\\/\\\\/t.co\\\\/flz6PNYM6T via @LifeZette\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/bufferapp.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eBuffer\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":50769180,\"id_str\":\"50769180\",\"name\":\"Laura Ingraham\",\"screen_name\":\"IngrahamAngle\",\"location\":\"DC\",\"url\":\"http:\\\\/\\\\/www.lauraingraham.com\",\"description\":\"Mom, Editor-in-Chief of LifeZette. Host, The Laura Ingraham Show, 9 to Noon ET. Listen live, join Laura365 to listen 24\\\\/7. Fox News. http:\\\\/\\\\/lauraingraham.com\",\"protected\":false,\"verified\":true,\"followers_count\":649781,\"friends_count\":335,\"listed_count\":8140,\"favourites_count\":61,\"statuses_count\":23801,\"created_at\":\"Thu Jun 25 21:03:25 +0000 2009\",\"utc_offset\":-18000,\"time_zone\":\"Eastern Time (US & Canada)\",\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"DBE9ED\",\"profile_background_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/450661623368146944\\\\/0SxSXve6.jpeg\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/450661623368146944\\\\/0SxSXve6.jpeg\",\"profile_background_tile\":false,\"profile_link_color\":\"CC3366\",\"profile_sidebar_border_color\":\"FFFFFF\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/418771110897782784\\\\/svOSjSLF_normal.jpeg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/418771110897782784\\\\/svOSjSLF_normal.jpeg\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":176,\"favorite_count\":160,\"entities\":{\"hashtags\":[],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/flz6PNYM6T\",\"expanded_url\":\"http:\\\\/\\\\/buff.ly\\\\/1XKy9QY\",\"display_url\":\"buff.ly\\\\/1XKy9QY\",\"indices\":[98,121]}],\"user_mentions\":[{\"screen_name\":\"LifeZette\",\"name\":\"LifeZette\",\"id\":3016071993,\"id_str\":\"3016071993\",\"indices\":[126,136]}],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\"},\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/flz6PNYM6T\",\"expanded_url\":\"http:\\\\/\\\\/buff.ly\\\\/1XKy9QY\",\"display_url\":\"buff.ly\\\\/1XKy9QY\",\"indices\":[117,140]}],\"user_mentions\":[{\"screen_name\":\"IngrahamAngle\",\"name\":\"Laura Ingraham\",\"id\":50769180,\"id_str\":\"50769180\",\"indices\":[3,17]},{\"screen_name\":\"LifeZette\",\"name\":\"LifeZette\",\"id\":3016071993,\"id_str\":\"3016071993\",\"indices\":[139,140]}],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1456249413514\"}',\n",
       " '{\"created_at\":\"Tue Feb 23 17:43:39 +0000 2016\",\"id\":702187073982181376,\"id_str\":\"702187073982181376\",\"text\":\"RT @Norsu2: Gov. Asa Hutchinson backs Marco Rubio\\'s presidential bid https:\\\\/\\\\/t.co\\\\/CBAboLCaqa #SEC https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/twitter.com\\\\/download\\\\/iphone\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eTwitter for iPhone\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":523409160,\"id_str\":\"523409160\",\"name\":\"Lissette Kron\",\"screen_name\":\"rightwinglatina\",\"location\":\"Las Vegas, NV\",\"url\":\"https:\\\\/\\\\/www.facebook.com\\\\/RightWingLatina\",\"description\":\"Homeschool mom. Tireless fighter against the Socialist-Marxist agenda. Passions #StopCommonCore #ProLife #Homeschool #SOSVzla #TeamMarco #NoCruz #NoTrump\",\"protected\":false,\"verified\":false,\"followers_count\":8954,\"friends_count\":9748,\"listed_count\":182,\"favourites_count\":12264,\"statuses_count\":46829,\"created_at\":\"Tue Mar 13 16:16:03 +0000 2012\",\"utc_offset\":-14400,\"time_zone\":\"Atlantic Time (Canada)\",\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/881869628\\\\/6b51f84915af234c94e6965ec60c3745.jpeg\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/881869628\\\\/6b51f84915af234c94e6965ec60c3745.jpeg\",\"profile_background_tile\":true,\"profile_link_color\":\"0084B4\",\"profile_sidebar_border_color\":\"FFFFFF\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":false,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/693171114550431744\\\\/sRsXm4OS_normal.jpg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/693171114550431744\\\\/sRsXm4OS_normal.jpg\",\"profile_banner_url\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/523409160\\\\/1456117597\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"retweeted_status\":{\"created_at\":\"Tue Feb 23 17:42:16 +0000 2016\",\"id\":702186729097318404,\"id_str\":\"702186729097318404\",\"text\":\"Gov. Asa Hutchinson backs Marco Rubio\\'s presidential bid https:\\\\/\\\\/t.co\\\\/CBAboLCaqa #SEC https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/bufferapp.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eBuffer\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":149315713,\"id_str\":\"149315713\",\"name\":\"Norsu\",\"screen_name\":\"Norsu2\",\"location\":\"Metro Boston #Cmass\",\"url\":\"http:\\\\/\\\\/httpmyblogblogspotcom-norsu.blogspot.com\\\\/\",\"description\":\"Taking our Country back one seat at a time. On a Mission to Bring Sanity to the discussion. On the side of Liberty vs Tyranny #teaparty #tcot #DumpTrump\",\"protected\":false,\"verified\":false,\"followers_count\":60927,\"friends_count\":62969,\"listed_count\":1033,\"favourites_count\":81047,\"statuses_count\":253853,\"created_at\":\"Sat May 29 00:15:29 +0000 2010\",\"utc_offset\":-18000,\"time_zone\":\"America\\\\/New_York\",\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"2C7599\",\"profile_background_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/378800000122300497\\\\/ab630f80598b2dba28eafaee7f0e157b.jpeg\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/378800000122300497\\\\/ab630f80598b2dba28eafaee7f0e157b.jpeg\",\"profile_background_tile\":true,\"profile_link_color\":\"3B94D9\",\"profile_sidebar_border_color\":\"000000\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/677611086397366272\\\\/U22e0Ywj_normal.jpg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/677611086397366272\\\\/U22e0Ywj_normal.jpg\",\"profile_banner_url\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/149315713\\\\/1420091150\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":2,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"SEC\",\"indices\":[81,85]}],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/CBAboLCaqa\",\"expanded_url\":\"http:\\\\/\\\\/buff.ly\\\\/1RZh3yj\",\"display_url\":\"buff.ly\\\\/1RZh3yj\",\"indices\":[57,80]}],\"user_mentions\":[],\"symbols\":[],\"media\":[{\"id\":702186728950513664,\"id_str\":\"702186728950513664\",\"indices\":[86,109],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"display_url\":\"pic.twitter.com\\\\/iEVgBjii0b\",\"expanded_url\":\"http:\\\\/\\\\/twitter.com\\\\/Norsu2\\\\/status\\\\/702186729097318404\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"small\":{\"w\":680,\"h\":453,\"resize\":\"fit\"},\"medium\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"}}}]},\"extended_entities\":{\"media\":[{\"id\":702186728950513664,\"id_str\":\"702186728950513664\",\"indices\":[86,109],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"display_url\":\"pic.twitter.com\\\\/iEVgBjii0b\",\"expanded_url\":\"http:\\\\/\\\\/twitter.com\\\\/Norsu2\\\\/status\\\\/702186729097318404\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"small\":{\"w\":680,\"h\":453,\"resize\":\"fit\"},\"medium\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"}}}]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\"},\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"SEC\",\"indices\":[93,97]}],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/CBAboLCaqa\",\"expanded_url\":\"http:\\\\/\\\\/buff.ly\\\\/1RZh3yj\",\"display_url\":\"buff.ly\\\\/1RZh3yj\",\"indices\":[69,92]}],\"user_mentions\":[{\"screen_name\":\"Norsu2\",\"name\":\"Norsu\",\"id\":149315713,\"id_str\":\"149315713\",\"indices\":[3,10]}],\"symbols\":[],\"media\":[{\"id\":702186728950513664,\"id_str\":\"702186728950513664\",\"indices\":[98,121],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"display_url\":\"pic.twitter.com\\\\/iEVgBjii0b\",\"expanded_url\":\"http:\\\\/\\\\/twitter.com\\\\/Norsu2\\\\/status\\\\/702186729097318404\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"small\":{\"w\":680,\"h\":453,\"resize\":\"fit\"},\"medium\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"}},\"source_status_id\":702186729097318404,\"source_status_id_str\":\"702186729097318404\",\"source_user_id\":149315713,\"source_user_id_str\":\"149315713\"}]},\"extended_entities\":{\"media\":[{\"id\":702186728950513664,\"id_str\":\"702186728950513664\",\"indices\":[98,121],\"media_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"media_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/media\\\\/Cb6rHBEWwAADxMk.jpg\",\"url\":\"https:\\\\/\\\\/t.co\\\\/iEVgBjii0b\",\"display_url\":\"pic.twitter.com\\\\/iEVgBjii0b\",\"expanded_url\":\"http:\\\\/\\\\/twitter.com\\\\/Norsu2\\\\/status\\\\/702186729097318404\\\\/photo\\\\/1\",\"type\":\"photo\",\"sizes\":{\"large\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"small\":{\"w\":680,\"h\":453,\"resize\":\"fit\"},\"medium\":{\"w\":746,\"h\":497,\"resize\":\"fit\"},\"thumb\":{\"w\":150,\"h\":150,\"resize\":\"crop\"}},\"source_status_id\":702186729097318404,\"source_status_id_str\":\"702186729097318404\",\"source_user_id\":149315713,\"source_user_id_str\":\"149315713\"}]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1456249419099\"}',\n",
       " '{\"created_at\":\"Tue Feb 23 17:44:21 +0000 2016\",\"id\":702187250835042304,\"id_str\":\"702187250835042304\",\"text\":\"If U want to talk ab \\\\\"free stuff,\\\\\" Hillary, talk about all the free stuff UR aiming to give your corporate cronies in tax breaks&amp;loopholes!\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/twitter.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eTwitter Web Client\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":1552125739,\"id_str\":\"1552125739\",\"name\":\"Alison Spalding\",\"screen_name\":\"AlisonSpalding2\",\"location\":\"Vista, California\",\"url\":\"https:\\\\/\\\\/twitter.com\\\\/AlisonSpalding3\",\"description\":\"Ph.D. MSW |Nice Enuf |USAF Vet| INFP|\\\\nLifelong,Proud #DemocraticSocialist\\\\nWE R THE RULING CLASS!\\\\n #PrivateCitizen #PoliticalRevolution  #FeelTheBern #NotWithHer\",\"protected\":false,\"verified\":false,\"followers_count\":7429,\"friends_count\":2614,\"listed_count\":332,\"favourites_count\":5180,\"statuses_count\":178290,\"created_at\":\"Fri Jun 28 03:28:45 +0000 2013\",\"utc_offset\":-25200,\"time_zone\":\"Arizona\",\"geo_enabled\":false,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"CC3366\",\"profile_background_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/378800000051978243\\\\/ee10d4cb8848b85fd7eefdb9881aa218.png\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/378800000051978243\\\\/ee10d4cb8848b85fd7eefdb9881aa218.png\",\"profile_background_tile\":false,\"profile_link_color\":\"4A913C\",\"profile_sidebar_border_color\":\"FFFFFF\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/681925072467066881\\\\/EoaKpuaL_normal.jpg\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/681925072467066881\\\\/EoaKpuaL_normal.jpg\",\"profile_banner_url\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_banners\\\\/1552125739\\\\/1376554299\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1456249461264\"}']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: visualize an element:\n",
    "rdd.sample(False, 1/1250).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Parse JSON strings to JSON objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Python has built-in support for JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.357132Z",
     "start_time": "2023-02-12T15:11:47.341936Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'name': 'A green door', 'price': 12.5, 'tags': ['home', 'green']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_example = '''\n",
    "{\n",
    "    \"id\": 1,\n",
    "    \"name\": \"A green door\",\n",
    "    \"price\": 12.50,\n",
    "    \"tags\": [\"home\", \"green\"]\n",
    "}\n",
    "'''\n",
    "\n",
    "json_obj = json.loads(json_example)\n",
    "json_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Broken tweets and irrelevant messages\n",
    "\n",
    "The data of this assignment may contain broken tweets (invalid JSON strings). So make sure that your code is robust for such cases.\n",
    "\n",
    "You can filter out such broken tweet by checking if:\n",
    "* the line is not in json format\n",
    "\n",
    "In addition, some lines in the input file might not be tweets, but messages that the Twitter server sent to the developer (such as limit notices). Your program should also ignore these messages.\n",
    "\n",
    "These messages would not contain the `created_at` field and can be filtered out accordingly.\n",
    "* Check if json object of the broken tweet has a `created_at` field\n",
    "\n",
    "**Hint:** [Catch the ValueError](http://stackoverflow.com/questions/11294535/verify-if-a-string-is-json-in-python)\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Parse raw JSON tweets stored in the RDD you created above to obtain **valid** JSON objects. \n",
    "1. From all valid tweets, construct a pair RDD of `(user_id, text)`, where `user_id` is the `id_str` data field of the `user` dictionary (read [Tweets](#Tweets) section above), `text` is the `text` data field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.398782Z",
     "start_time": "2023-02-12T15:11:47.362352Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def safe_parse(raw_json):\n",
    "    \"\"\"\n",
    "    Input is a String\n",
    "    Output is a JSON object if the tweet is valid and None if not valid\n",
    "    \"\"\"\n",
    "\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    \n",
    "    # Test if a raw_json is valid json. Returns None if not valid  \n",
    "    try:\n",
    "        json_object = json.loads(raw_json)\n",
    "    except ValueError as e:\n",
    "        #print('Invalid input string.')\n",
    "        return None\n",
    "    \n",
    "    # Test if \"created_at\" key is in json_object. Returns None if not.\n",
    "    if \"created_at\" in json_object:\n",
    "        return json_object\n",
    "    else:\n",
    "        #print('\"created_at\" key not found.')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.540802Z",
     "start_time": "2023-02-12T15:11:47.410088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at  =>  Tue Feb 23 17:42:36 +0000 2016\n",
      "id  =>  702186809468526592\n",
      "id_str  =>  702186809468526592\n",
      "text  =>  RT @C0nservativeGal: Well , I'm Conservative Southern Bapist and I'm 4 #Trump-Southern Baptist leader: Donald Trump is not our friend https…\n",
      "source  =>  <a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for Windows</a>\n",
      "truncated  =>  False\n",
      "in_reply_to_status_id  =>  None\n",
      "in_reply_to_status_id_str  =>  None\n",
      "in_reply_to_user_id  =>  None\n",
      "in_reply_to_user_id_str  =>  None\n",
      "in_reply_to_screen_name  =>  None\n",
      "user  =>  {'id': 229594092, 'id_str': '229594092', 'name': 'paul wagner', 'screen_name': 'bearbear9876', 'location': None, 'url': None, 'description': None, 'protected': False, 'verified': False, 'followers_count': 47, 'friends_count': 24, 'listed_count': 6, 'favourites_count': 1846, 'statuses_count': 2849, 'created_at': 'Wed Dec 22 20:25:15 +0000 2010', 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'lang': 'en', 'contributors_enabled': False, 'is_translator': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_link_color': '0084B4', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_0_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_0_normal.png', 'default_profile': True, 'default_profile_image': True, 'following': None, 'follow_request_sent': None, 'notifications': None}\n",
      "geo  =>  None\n",
      "coordinates  =>  None\n",
      "place  =>  None\n",
      "contributors  =>  None\n",
      "retweeted_status  =>  {'created_at': 'Tue Feb 23 17:14:11 +0000 2016', 'id': 702179658717077504, 'id_str': '702179658717077504', 'text': \"Well , I'm Conservative Southern Bapist and I'm 4 #Trump-Southern Baptist leader: Donald Trump is not our friend https://t.co/nYUt4qn6S9\", 'source': '<a href=\"http://mobile.twitter.com\" rel=\"nofollow\">Mobile Web</a>', 'truncated': False, 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 185906955, 'id_str': '185906955', 'name': 'Johanna', 'screen_name': 'C0nservativeGal', 'location': 'USA', 'url': 'http://uspresidentialelectionnews.com', 'description': \"I'm a kick ass conservachick whose mission is to secure freedom, eliminate liberalism and look good doing it! No DMs #Christian #WhoDatNation #Trump2016\", 'protected': False, 'verified': False, 'followers_count': 34822, 'friends_count': 28947, 'listed_count': 306, 'favourites_count': 19910, 'statuses_count': 31801, 'created_at': 'Thu Sep 02 03:13:57 +0000 2010', 'utc_offset': -18000, 'time_zone': 'Eastern Time (US & Canada)', 'geo_enabled': False, 'lang': 'en', 'contributors_enabled': False, 'is_translator': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/687403539/729718c7391e53acaf7d6ac43f3c959e.jpeg', 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/687403539/729718c7391e53acaf7d6ac43f3c959e.jpeg', 'profile_background_tile': True, 'profile_link_color': 'E854E8', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'profile_image_url': 'http://pbs.twimg.com/profile_images/688571288563003392/HXtUWGWa_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/688571288563003392/HXtUWGWa_normal.png', 'default_profile': False, 'default_profile_image': False, 'following': None, 'follow_request_sent': None, 'notifications': None}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 32, 'favorite_count': 43, 'entities': {'hashtags': [{'text': 'Trump', 'indices': [50, 56]}], 'urls': [{'url': 'https://t.co/nYUt4qn6S9', 'expanded_url': 'http://www.al.com/news/index.ssf/2015/09/southern_baptist_leader_donald.html', 'display_url': 'al.com/news/index.ssf…', 'indices': [113, 136]}], 'user_mentions': [], 'symbols': []}, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'filter_level': 'low', 'lang': 'en'}\n",
      "is_quote_status  =>  False\n",
      "retweet_count  =>  0\n",
      "favorite_count  =>  0\n",
      "entities  =>  {'hashtags': [{'text': 'Trump', 'indices': [71, 77]}], 'urls': [{'url': 'https://t.co/nYUt4qn6S9', 'expanded_url': 'http://www.al.com/news/index.ssf/2015/09/southern_baptist_leader_donald.html', 'display_url': 'al.com/news/index.ssf…', 'indices': [139, 140]}], 'user_mentions': [{'screen_name': 'C0nservativeGal', 'name': 'Johanna', 'id': 185906955, 'id_str': '185906955', 'indices': [3, 19]}], 'symbols': []}\n",
      "favorited  =>  False\n",
      "retweeted  =>  False\n",
      "possibly_sensitive  =>  False\n",
      "filter_level  =>  low\n",
      "lang  =>  en\n",
      "timestamp_ms  =>  1456249356034\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "'''safe_parse('{}')              # prints True\n",
    "safe_parse('{asdf}')          # prints False\n",
    "safe_parse('{\"age\":100}')     # prints True\n",
    "safe_parse('{age:100 }')      # prints False\n",
    "safe_parse('{\"age\":100 }')    # prints True'''\n",
    "\n",
    "test_string = '{\"created_at\":\"Tue Feb 23 17:42:36 +0000 2016\",\"id\":702186809468526592,\"id_str\":\"702186809468526592\",\"text\":\"RT @C0nservativeGal: Well , I\\'m Conservative Southern Bapist and I\\'m 4 #Trump-Southern Baptist leader: Donald Trump is not our friend https\\\\u2026\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/www.twitter.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eTwitter for Windows\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":229594092,\"id_str\":\"229594092\",\"name\":\"paul wagner\",\"screen_name\":\"bearbear9876\",\"location\":null,\"url\":null,\"description\":null,\"protected\":false,\"verified\":false,\"followers_count\":47,\"friends_count\":24,\"listed_count\":6,\"favourites_count\":1846,\"statuses_count\":2849,\"created_at\":\"Wed Dec 22 20:25:15 +0000 2010\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/abs.twimg.com\\\\/images\\\\/themes\\\\/theme1\\\\/bg.png\",\"profile_background_tile\":false,\"profile_link_color\":\"0084B4\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/abs.twimg.com\\\\/sticky\\\\/default_profile_images\\\\/default_profile_0_normal.png\",\"profile_image_url_https\":\"https:\\\\/\\\\/abs.twimg.com\\\\/sticky\\\\/default_profile_images\\\\/default_profile_0_normal.png\",\"default_profile\":true,\"default_profile_image\":true,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"retweeted_status\":{\"created_at\":\"Tue Feb 23 17:14:11 +0000 2016\",\"id\":702179658717077504,\"id_str\":\"702179658717077504\",\"text\":\"Well , I\\'m Conservative Southern Bapist and I\\'m 4 #Trump-Southern Baptist leader: Donald Trump is not our friend https:\\\\/\\\\/t.co\\\\/nYUt4qn6S9\",\"source\":\"\\\\u003ca href=\\\\\"http:\\\\/\\\\/mobile.twitter.com\\\\\" rel=\\\\\"nofollow\\\\\"\\\\u003eMobile Web\\\\u003c\\\\/a\\\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":185906955,\"id_str\":\"185906955\",\"name\":\"Johanna\",\"screen_name\":\"C0nservativeGal\",\"location\":\"USA\",\"url\":\"http:\\\\/\\\\/uspresidentialelectionnews.com\",\"description\":\"I\\'m a kick ass conservachick whose mission is to secure freedom, eliminate liberalism and look good doing it! No DMs #Christian #WhoDatNation #Trump2016\",\"protected\":false,\"verified\":false,\"followers_count\":34822,\"friends_count\":28947,\"listed_count\":306,\"favourites_count\":19910,\"statuses_count\":31801,\"created_at\":\"Thu Sep 02 03:13:57 +0000 2010\",\"utc_offset\":-18000,\"time_zone\":\"Eastern Time (US & Canada)\",\"geo_enabled\":false,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/687403539\\\\/729718c7391e53acaf7d6ac43f3c959e.jpeg\",\"profile_background_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_background_images\\\\/687403539\\\\/729718c7391e53acaf7d6ac43f3c959e.jpeg\",\"profile_background_tile\":true,\"profile_link_color\":\"E854E8\",\"profile_sidebar_border_color\":\"000000\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/688571288563003392\\\\/HXtUWGWa_normal.png\",\"profile_image_url_https\":\"https:\\\\/\\\\/pbs.twimg.com\\\\/profile_images\\\\/688571288563003392\\\\/HXtUWGWa_normal.png\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":32,\"favorite_count\":43,\"entities\":{\"hashtags\":[{\"text\":\"Trump\",\"indices\":[50,56]}],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/nYUt4qn6S9\",\"expanded_url\":\"http:\\\\/\\\\/www.al.com\\\\/news\\\\/index.ssf\\\\/2015\\\\/09\\\\/southern_baptist_leader_donald.html\",\"display_url\":\"al.com\\\\/news\\\\/index.ssf\\\\u2026\",\"indices\":[113,136]}],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\"},\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[{\"text\":\"Trump\",\"indices\":[71,77]}],\"urls\":[{\"url\":\"https:\\\\/\\\\/t.co\\\\/nYUt4qn6S9\",\"expanded_url\":\"http:\\\\/\\\\/www.al.com\\\\/news\\\\/index.ssf\\\\/2015\\\\/09\\\\/southern_baptist_leader_donald.html\",\"display_url\":\"al.com\\\\/news\\\\/index.ssf\\\\u2026\",\"indices\":[139,140]}],\"user_mentions\":[{\"screen_name\":\"C0nservativeGal\",\"name\":\"Johanna\",\"id\":185906955,\"id_str\":\"185906955\",\"indices\":[3,19]}],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1456249356034\"}'\n",
    "test_json_object = safe_parse(test_string)\n",
    "#print(test_json_object)\n",
    "if test_json_object is None:\n",
    "    print(test_json_object)\n",
    "else:\n",
    "    for k, v in test_json_object.items():\n",
    "        print(k, ' => ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:47.565078Z",
     "start_time": "2023-02-12T15:11:47.549049Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Remember to construct an RDD of (user_id, text) here.\n",
    "\"\"\"\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "rdd_valid_tweets = rdd.map(safe_parse).filter(lambda x: x!=None).map(lambda x: (x['user']['id_str'], x['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:48.554180Z",
     "start_time": "2023-02-12T15:11:47.571389Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n = rdd_valid_tweets.count()\\nprint('Number of elements: ', n)\\n\\nm = 5\\nrdd_sample = rdd_valid_tweets.sample(False, m/n).collect()\\nprint(f'A sample of {len(rdd_sample)} elements:\\n')\\nfor item in rdd_sample:\\n    print(item)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests\n",
    "'''n = rdd_valid_tweets.count()\n",
    "print('Number of elements: ', n)\n",
    "\n",
    "m = 5\n",
    "rdd_sample = rdd_valid_tweets.sample(False, m/n).collect()\n",
    "print(f'A sample of {len(rdd_sample)} elements:\\n')\n",
    "for item in rdd_sample:\n",
    "    print(item)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Number of unique users\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Count the number of different users in all valid tweets and store the result in `num_unique_users`.\n",
    "\n",
    "**Hint:** use the [`distinct()`](https://spark.apache.org/docs/2.3.0/api/python/pyspark.html#pyspark.RDD.distinct) method.\n",
    "\n",
    "***\n",
    "\n",
    "**It should print**\n",
    "```\n",
    "The number of unique users is: 1748\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:49.303988Z",
     "start_time": "2023-02-12T15:11:48.562010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is: 1748\n"
     ]
    }
   ],
   "source": [
    "save_time(\"count unique users\")\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "num_unique_users = rdd_valid_tweets.map(lambda x: x[0]).distinct().count()\n",
    "\n",
    "my_output.append(\"num-unique-users\", num_unique_users)\n",
    "print('The number of unique users is:', num_unique_users)\n",
    "save_time(\"count unique users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Number of posts from each user partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Load the pickle file\n",
    "\n",
    "Load the Pickle file `users-partition.pickle`, you will get a dictionary which represents a partition over 452,743 Twitter users, `{user_id: partition_id}`. The users are partitioned into 7 groups. For example, if the dictionary is loaded into a variable named `partition`, the partition ID of the user `59458445` is `partition[\"59458445\"]`. These users are partitioned into 7 groups. The partition ID is an integer between 0-6.\n",
    "\n",
    "Note that the user partition we provide doesn't cover all users appear in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:49.891547Z",
     "start_time": "2023-02-12T15:11:49.309043Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452743"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "if ON_EMR:\n",
    "    command = [\"/usr/local/hadoop/hadoop-2.7.4/bin/hadoop\", \"fs\", \"-cat\", \"/user/spark/twitter/users-partition.pickle\"]\n",
    "else:\n",
    "    command = [\"cat\", \"./resource/asnlib/publicdata/users-partition.pickle\"]\n",
    "    \n",
    "proc = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "pickle_content = proc.communicate()[0]\n",
    "partition = pickle.loads(pickle_content)\n",
    "len(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Tweets per user partition\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Count the number of posts from group 0, 1, ..., 6, plus the number of posts from users who are not in any partition. Assign users who are not in any partition to the group 7.\n",
    "1. Put the results of this step into a pair RDD `(group_id, count)` that is sorted by key.\n",
    "1. Collect the RDD to get `counts_per_part` list.\n",
    "\n",
    "***\n",
    "\n",
    "**It should print**\n",
    "\n",
    "```\n",
    "Group 0 posted 87 tweets\n",
    "Group 1 posted 242 tweets\n",
    "Group 2 posted 41 tweets\n",
    "Group 3 posted 349 tweets\n",
    "Group 4 posted 101 tweets\n",
    "Group 5 posted 358 tweets\n",
    "Group 6 posted 434 tweets\n",
    "Group 7 posted 521 tweets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:49.905929Z",
     "start_time": "2023-02-12T15:11:49.898101Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def print_post_count(counts):\n",
    "    for group_id, count in counts:\n",
    "        print('Group %d posted %d tweets' % (group_id, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:57.953594Z",
     "start_time": "2023-02-12T15:11:49.911102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 posted 87 tweets\n",
      "Group 1 posted 242 tweets\n",
      "Group 2 posted 41 tweets\n",
      "Group 3 posted 349 tweets\n",
      "Group 4 posted 101 tweets\n",
      "Group 5 posted 358 tweets\n",
      "Group 6 posted 434 tweets\n",
      "Group 7 posted 521 tweets\n"
     ]
    }
   ],
   "source": [
    "save_time(\"count tweets per user partition\")\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# Convert partition dict to (key, val) RDD \n",
    "rdd_partition = sc.parallelize(partition.items())\n",
    "\n",
    "# Left Outer Join rdd_valid_tweets with rdd_partition based on user_id. If user_id not found in rdd_partition assign 7 as partition\n",
    "rdd_lojoin_by_user_id = rdd_valid_tweets.leftOuterJoin(rdd_partition)\n",
    "rdd_by_partition = rdd_lojoin_by_user_id.map(lambda x: (x[1][1] if x[1][1] in range(7) else 7, [x[0], x[1][0]]))\n",
    "rdd_counts_per_part = sc.parallelize(rdd_by_partition.countByKey().items()).sortByKey()\n",
    "counts_per_part = rdd_counts_per_part.collect()\n",
    "\n",
    "# Following code adds your solution to `my_output`\n",
    "assert(type(counts_per_part) is list and\n",
    "       len(counts_per_part) == 8 and\n",
    "       len(counts_per_part[0]) == 2)\n",
    "print_post_count(counts_per_part)\n",
    "my_output.append(\"counts_per_part\", counts_per_part)\n",
    "save_time(\"count tweets per user partition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part 3:  Tokens that are relatively popular in each user partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this step, we are going to find tokens that are relatively popular in each user partition.\n",
    "\n",
    "We define the number of mentions of a token $t$ in a specific user partition $k$ as the number of users from the user partition $k$ that ever mentioned the token $t$ in their tweets. Note that even if some users might mention a token $t$ multiple times or in multiple tweets, a user will contribute at most 1 to the counter of the token $t$.\n",
    "\n",
    "Please make sure that the number of mentions of a token is equal to the number of users who mentioned this token but NOT the number of tweets that mentioned this token.\n",
    "\n",
    "Let $N_t^k$ be the number of mentions of the token $t$ in the user partition $k$. Let $N_t^{all} = \\sum_{i=0}^7 N_t^{i}$ be the number of total mentions of the token $t$.\n",
    "\n",
    "We define the relative popularity of a token $t$ in a user partition $k$ as the log ratio between $N_t^k$ and $N_t^{all}$, i.e. \n",
    "\n",
    "\\begin{equation}\n",
    "p_t^k = \\log \\frac{N_t^k}{N_t^{all}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "You can compute the relative popularity by calling the function `get_rel_popularity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We load a tweet tokenizer for you in the following cells. This Tokenizer object is called `tok`. Don't forget to execute the two cells below.\n",
    "\n",
    "You can expand the following cell if needed to see the minutae of the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:59.357629Z",
     "start_time": "2023-02-12T15:11:57.968487Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "This code implements a basic, Twitter-aware tokenizer.\n",
    "\n",
    "A tokenizer is a function that splits a string of text into words. In\n",
    "Python terms, we map string and unicode objects into lists of unicode\n",
    "objects.\n",
    "\n",
    "There is not a single right way to do tokenizing. The best method\n",
    "depends on the application.  This tokenizer is designed to be flexible\n",
    "and this easy to adapt to new domains and tasks.  The basic logic is\n",
    "this:\n",
    "\n",
    "1. The tuple regex_strings defines a list of regular expression\n",
    "   strings.\n",
    "\n",
    "2. The regex_strings strings are put, in order, into a compiled\n",
    "   regular expression object called word_re.\n",
    "\n",
    "3. The tokenization is done by word_re.findall(s), where s is the\n",
    "   user-supplied string, inside the tokenize() method of the class\n",
    "   Tokenizer.\n",
    "\n",
    "4. When instantiating Tokenizer objects, there is a single option:\n",
    "   preserve_case.  By default, it is set to True. If it is set to\n",
    "   False, then the tokenizer will downcase everything except for\n",
    "   emoticons.\n",
    "\n",
    "The __main__ method illustrates by tokenizing a few examples.\n",
    "\n",
    "I've also included a Tokenizer method tokenize_random_tweet(). If the\n",
    "twitter library is installed (http://code.google.com/p/python-twitter/)\n",
    "and Twitter is cooperating, then it should tokenize a random\n",
    "English-language tweet.\n",
    "\n",
    "\n",
    "Julaiti Alafate:\n",
    "  I modified the regex strings to extract URLs in tweets.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Christopher Potts\"\n",
    "__copyright__ = \"Copyright 2011, Christopher Potts\"\n",
    "__credits__ = []\n",
    "__license__ = \"Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License: http://creativecommons.org/licenses/by-nc-sa/3.0/\"\n",
    "__version__ = \"1.0\"\n",
    "__maintainer__ = \"Christopher Potts\"\n",
    "__email__ = \"See the author's website\"\n",
    "\n",
    "######################################################################\n",
    "\n",
    "import re\n",
    "from html import entities \n",
    "\n",
    "######################################################################\n",
    "# The following strings are components in the regular expression\n",
    "# that is used for tokenizing. It's important that phone_number\n",
    "# appears first in the final regex (since it can contain whitespace).\n",
    "# It also could matter that tags comes after emoticons, due to the\n",
    "# possibility of having text like\n",
    "#\n",
    "#     <:| and some text >:)\n",
    "#\n",
    "# Most imporatantly, the final element should always be last, since it\n",
    "# does a last ditch whitespace-based tokenization of whatever is left.\n",
    "\n",
    "# This particular element is used in a couple ways, so we define it\n",
    "# with a name:\n",
    "emoticon_string = r\"\"\"\n",
    "    (?:\n",
    "      [<>]?\n",
    "      [:;=8]                     # eyes\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth      \n",
    "      |\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [:;=8]                     # eyes\n",
    "      [<>]?\n",
    "    )\"\"\"\n",
    "\n",
    "# The components of the tokenizer:\n",
    "regex_strings = (\n",
    "    # Phone numbers:\n",
    "    r\"\"\"\n",
    "    (?:\n",
    "      (?:            # (international)\n",
    "        \\+?[01]\n",
    "        [\\-\\s.]*\n",
    "      )?            \n",
    "      (?:            # (area code)\n",
    "        [\\(]?\n",
    "        \\d{3}\n",
    "        [\\-\\s.\\)]*\n",
    "      )?    \n",
    "      \\d{3}          # exchange\n",
    "      [\\-\\s.]*   \n",
    "      \\d{4}          # base\n",
    "    )\"\"\"\n",
    "    ,\n",
    "    # URLs:\n",
    "    r\"\"\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\"\"\n",
    "    ,\n",
    "    # Emoticons:\n",
    "    emoticon_string\n",
    "    ,    \n",
    "    # HTML tags:\n",
    "     r\"\"\"<[^>]+>\"\"\"\n",
    "    ,\n",
    "    # Twitter username:\n",
    "    r\"\"\"(?:@[\\w_]+)\"\"\"\n",
    "    ,\n",
    "    # Twitter hashtags:\n",
    "    r\"\"\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\"\"\"\n",
    "    ,\n",
    "    # Remaining word types:\n",
    "    r\"\"\"\n",
    "    (?:[a-z][a-z'\\-_]+[a-z])       # Words with apostrophes or dashes.\n",
    "    |\n",
    "    (?:[+\\-]?\\d+[,/.:-]\\d+[+\\-]?)  # Numbers, including fractions, decimals.\n",
    "    |\n",
    "    (?:[\\w_]+)                     # Words without apostrophes or dashes.\n",
    "    |\n",
    "    (?:\\.(?:\\s*\\.){1,})            # Ellipsis dots. \n",
    "    |\n",
    "    (?:\\S)                         # Everything else that isn't whitespace.\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "######################################################################\n",
    "# This is the core tokenizing regex:\n",
    "    \n",
    "word_re = re.compile(r\"\"\"(%s)\"\"\" % \"|\".join(regex_strings), re.VERBOSE | re.I | re.UNICODE)\n",
    "\n",
    "# The emoticon string gets its own regex so that we can preserve case for them as needed:\n",
    "emoticon_re = re.compile(regex_strings[1], re.VERBOSE | re.I | re.UNICODE)\n",
    "\n",
    "# These are for regularizing HTML entities to Unicode:\n",
    "html_entity_digit_re = re.compile(r\"&#\\d+;\")\n",
    "html_entity_alpha_re = re.compile(r\"&\\w+;\")\n",
    "amp = \"&amp;\"\n",
    "\n",
    "######################################################################\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, preserve_case=False):\n",
    "        self.preserve_case = preserve_case\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        \"\"\"\n",
    "        Argument: s -- any string or unicode object\n",
    "        Value: a tokenize list of strings; conatenating this list returns the original string if preserve_case=False\n",
    "        \"\"\"        \n",
    "        # Try to ensure unicode:\n",
    "        try:\n",
    "            s = str(s)\n",
    "        except UnicodeDecodeError:\n",
    "            s = s.encode('string_escape')\n",
    "            s = str(s)\n",
    "        # Fix HTML character entitites:\n",
    "        s = self.__html2unicode(s)\n",
    "        # Tokenize:\n",
    "        words = word_re.findall(s)\n",
    "        # Possible alter the case, but avoid changing emoticons like :D into :d:\n",
    "        if not self.preserve_case:            \n",
    "            words = list(map((lambda x : x if emoticon_re.search(x) else x.lower()), words))\n",
    "        return words\n",
    "\n",
    "    def tokenize_random_tweet(self):\n",
    "        \"\"\"\n",
    "        If the twitter library is installed and a twitter connection\n",
    "        can be established, then tokenize a random tweet.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import twitter\n",
    "        except ImportError:\n",
    "            print(\"Apologies. The random tweet functionality requires the Python twitter library: http://code.google.com/p/python-twitter/\")\n",
    "        from random import shuffle\n",
    "        api = twitter.Api()\n",
    "        tweets = api.GetPublicTimeline()\n",
    "        if tweets:\n",
    "            for tweet in tweets:\n",
    "                if tweet.user.lang == 'en':            \n",
    "                    return self.tokenize(tweet.text)\n",
    "        else:\n",
    "            raise Exception(\"Apologies. I couldn't get Twitter to give me a public English-language tweet. Perhaps try again\")\n",
    "\n",
    "    def __html2unicode(self, s):\n",
    "        \"\"\"\n",
    "        Internal metod that seeks to replace all the HTML entities in\n",
    "        s with their corresponding unicode characters.\n",
    "        \"\"\"\n",
    "        # First the digits:\n",
    "        ents = set(html_entity_digit_re.findall(s))\n",
    "        if len(ents) > 0:\n",
    "            for ent in ents:\n",
    "                entnum = ent[2:-1]\n",
    "                try:\n",
    "                    entnum = int(entnum)\n",
    "                    s = s.replace(ent, unichr(entnum))\t\n",
    "                except:\n",
    "                    pass\n",
    "        # Now the alpha versions:\n",
    "        ents = set(html_entity_alpha_re.findall(s))\n",
    "        ents = filter((lambda x : x != amp), ents)\n",
    "        for ent in ents:\n",
    "            entname = ent[1:-1]\n",
    "            try:            \n",
    "                s = s.replace(ent, unichr(entities.name2codepoint[entname]))\n",
    "            except:\n",
    "                pass                    \n",
    "            s = s.replace(amp, \" and \")\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:11:59.951427Z",
     "start_time": "2023-02-12T15:11:59.373985Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "tok = Tokenizer(preserve_case=False)\n",
    "\n",
    "def get_rel_popularity(c_k, c_all):\n",
    "    '''\n",
    "    Compute the relative popularity of a token.\n",
    "    \n",
    "    Args:\n",
    "        c_k: the number of mentions in the user partition k.\n",
    "        c_all: the number of all mentions.\n",
    "        \n",
    "    Return:\n",
    "        The relative popularity of the token. It should be a negative number due to the log function. \n",
    "    '''\n",
    "    \n",
    "    return log(1.0 * c_k / c_all) / log(2)\n",
    "\n",
    "def print_tokens(tokens, gid=None):\n",
    "    group_name = \"overall\"\n",
    "    if gid is not None:\n",
    "        group_name = \"group %d\" % gid\n",
    "        \n",
    "    print('=' * 5 + ' ' + group_name + ' ' + '=' * 5)\n",
    "    for t, n in tokens:\n",
    "        print(\"%s\\t%.4f\" % (t, n))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Tokenize tweets\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Tokenize the tweets using the `tokenize` function that is a method of the `Tokenizer` class that we have instantiated as `tok`. \n",
    "1. Count the number of mentions for each tokens regardless of specific user group and store them in a RDD, which will be used later.\n",
    "1. Get `num_of_tokens`, which is how many different tokens we have.\n",
    "\n",
    "---\n",
    "\n",
    "**It should print**\n",
    "```\n",
    "Number of tokens: 7677\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:12:05.768637Z",
     "start_time": "2023-02-12T15:11:59.957381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 7677\n"
     ]
    }
   ],
   "source": [
    "save_time(\"count all unique tokens\")\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# Tokenize tweets\n",
    "rdd_tok = rdd_by_partition.flatMap(lambda x: tok.tokenize(x[1][1]))\n",
    "\n",
    "# Count tokens\n",
    "rdd_tok_val = rdd_tok.map(lambda tok: (tok, 1))\n",
    "rdd_counts_tok = rdd_tok_val.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Get num_of_tokens\n",
    "num_of_tokens = rdd_counts_tok.distinct().count()\n",
    "\n",
    "my_output.append(\"num-tokens\", num_of_tokens)\n",
    "print(\"Number of tokens:\", num_of_tokens)\n",
    "save_time(\"count all unique tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Token popularity\n",
    "\n",
    "Tokens that are mentioned by too few users are usually not very interesting. So we want to only keep tokens that are mentioned by at least 100 users. Filter out tokens that don't meet this requirement.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Compute the two varaibles below:\n",
    "    1. `num_freq_tokens`: an int of how many different tokens we have after the filtering. \n",
    "    1. `top20`: a list that contains the top 20 most frequent tokens after the filtering.\n",
    "\n",
    "---\n",
    "\n",
    "**It should print**\n",
    "```\n",
    "Number of tokens: 46\n",
    "===== overall =====\n",
    ":\t1046.0000\n",
    "rt\t920.0000\n",
    ".\t767.0000\n",
    "the\t587.0000\n",
    "trump\t560.0000\n",
    "…\t520.0000\n",
    "to\t501.0000\n",
    ",\t497.0000\n",
    "in\t385.0000\n",
    "a\t383.0000\n",
    "is\t382.0000\n",
    "of\t300.0000\n",
    "!\t285.0000\n",
    "for\t275.0000\n",
    "and\t263.0000\n",
    "on\t218.0000\n",
    "i\t216.0000\n",
    "he\t191.0000\n",
    "that\t190.0000\n",
    "\"\t181.0000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:12:11.140956Z",
     "start_time": "2023-02-12T15:12:05.773436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 46\n",
      "===== overall =====\n",
      ":\t1046.0000\n",
      "rt\t920.0000\n",
      ".\t767.0000\n",
      "the\t587.0000\n",
      "trump\t560.0000\n",
      "…\t520.0000\n",
      "to\t501.0000\n",
      ",\t497.0000\n",
      "in\t385.0000\n",
      "a\t383.0000\n",
      "is\t382.0000\n",
      "of\t300.0000\n",
      "!\t285.0000\n",
      "for\t275.0000\n",
      "and\t263.0000\n",
      "on\t218.0000\n",
      "i\t216.0000\n",
      "he\t191.0000\n",
      "that\t190.0000\n",
      "\"\t181.0000\n"
     ]
    }
   ],
   "source": [
    "save_time(\"count overall most popular tokens\")\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# Create RDD mapping each token to each user_id. Eliminate duplicates i.e. keep unique pairs (token, user_id).\n",
    "rdd_tok_by_users = rdd_by_partition.flatMap(lambda x: [(t, x[1][0]) for t in tok.tokenize(x[1][1])]).distinct()\n",
    "\n",
    "# Create RDD counting the number of unique user_id which mention each token.\n",
    "rdd_tok_by_user_count = rdd_tok_by_users.groupByKey().map(lambda x: (x[0], len([i for i in x[1]])))\n",
    "\n",
    "# Filter tokens mentioned at least by 100 users. Sort by highest occurence.\n",
    "rdd_tok_by_user_count_filt = rdd_tok_by_user_count.filter(lambda x: x[1] >= 100).sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Get number of tokens mentioned at least by 100 users\n",
    "num_freq_tokens = rdd_tok_by_user_count_filt.count()\n",
    "\n",
    "# Get a list of top 20 most frequent tokens\n",
    "top20 = rdd_tok_by_user_count_filt.take(20)\n",
    "\n",
    "my_output.append(\"num-freq-tokens\", num_freq_tokens)\n",
    "my_output.append(\"top-20-tokens\", top20)\n",
    "print(\"Number of tokens:\", num_freq_tokens)\n",
    "print_tokens(top20)\n",
    "save_time(\"count overall most popular tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Relative Popularity\n",
    "\n",
    "For all tokens that are mentioned by at least 100 users, compute their relative popularity in each user group. Then print the top 10 tokens with highest relative popularity in each user group. In case two tokens have same relative popularity, break the tie by printing the alphabetically smaller one first.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Calculate `popular_10_in_each_group` list, in which the `i`-th element is a list of 10 (token, relative popularity) pair that are top 10 tokens with highest relative popularity in the `i`-th user group.\n",
    "\n",
    "**Hint:** Let the relative popularity of a token $t$ be $p$. The order of the items will be satisfied by sorting them using (-p, t) as the key.\n",
    "\n",
    "---\n",
    "\n",
    "**It should print**\n",
    "```\n",
    "===== group 0 =====\n",
    "with\t-3.6088\n",
    "cruz\t-3.6554\n",
    "his\t-3.6582\n",
    "amp\t-3.8651\n",
    "on\t-3.9608\n",
    "to\t-4.0145\n",
    "&\t-4.0875\n",
    "https\t-4.1699\n",
    "i\t-4.1699\n",
    "what\t-4.1699\n",
    "===== group 1 =====\n",
    "sanders\t-2.2854\n",
    "gop\t-2.4060\n",
    "hillary\t-2.4330\n",
    "’\t-2.4463\n",
    "bernie\t-2.4835\n",
    "\"\t-2.6925\n",
    "are\t-2.7249\n",
    "this\t-2.7633\n",
    "for\t-2.8179\n",
    "about\t-2.8346\n",
    "===== group 2 =====\n",
    "with\t-4.3458\n",
    "donald\t-4.5146\n",
    "...\t-4.7004\n",
    "gop\t-4.7279\n",
    "i\t-4.9475\n",
    "on\t-4.9608\n",
    "he\t-4.9925\n",
    "…\t-5.1155\n",
    "https\t-5.1699\n",
    "what\t-5.1699\n",
    "===== group 3 =====\n",
    "bernie\t-1.5945\n",
    "sanders\t-1.6609\n",
    "hillary\t-2.2188\n",
    "and\t-2.5154\n",
    "\"\t-2.5930\n",
    "in\t-2.6114\n",
    "will\t-2.6160\n",
    "https\t-2.6674\n",
    "...\t-2.7004\n",
    "you\t-2.7004\n",
    "===== group 4 =====\n",
    "what\t-3.4330\n",
    "have\t-3.4725\n",
    "bernie\t-3.5380\n",
    "this\t-3.5518\n",
    "it\t-3.6881\n",
    "?\t-3.6912\n",
    "for\t-3.7110\n",
    "about\t-3.7415\n",
    "hillary\t-3.7549\n",
    "that\t-3.7625\n",
    "===== group 5 =====\n",
    "what\t-1.8007\n",
    "not\t-1.8745\n",
    "https\t-2.0000\n",
    "his\t-2.0144\n",
    "cruz\t-2.0704\n",
    "it\t-2.1031\n",
    "on\t-2.1243\n",
    "&\t-2.1399\n",
    "amp\t-2.1489\n",
    ";\t-2.1592\n",
    "===== group 6 =====\n",
    "will\t-1.3847\n",
    "have\t-1.4725\n",
    "!\t-1.5850\n",
    "cruz\t-1.6919\n",
    "trump\t-1.7199\n",
    "https\t-1.7549\n",
    "-\t-1.7673\n",
    ";\t-1.7807\n",
    "be\t-1.7952\n",
    "amp\t-1.8144\n",
    "===== group 7 =====\n",
    "donald\t-1.0740\n",
    "trump\t-1.6535\n",
    "bernie\t-1.7790\n",
    "sanders\t-1.7829\n",
    "’\t-1.8613\n",
    "of\t-1.9069\n",
    "?\t-1.9186\n",
    "with\t-1.9307\n",
    "the\t-1.9588\n",
    "be\t-1.9758\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:12:16.366755Z",
     "start_time": "2023-02-12T15:12:11.146340Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== group 0 =====\n",
      "with\t-3.6088\n",
      "cruz\t-3.6554\n",
      "his\t-3.6582\n",
      "amp\t-3.8651\n",
      "on\t-3.9608\n",
      "to\t-4.0145\n",
      "&\t-4.0875\n",
      "https\t-4.1699\n",
      "i\t-4.1699\n",
      "what\t-4.1699\n",
      "===== group 1 =====\n",
      "sanders\t-2.2854\n",
      "gop\t-2.4060\n",
      "hillary\t-2.4330\n",
      "’\t-2.4463\n",
      "bernie\t-2.4835\n",
      "\"\t-2.6925\n",
      "are\t-2.7249\n",
      "this\t-2.7633\n",
      "for\t-2.8179\n",
      "about\t-2.8346\n",
      "===== group 2 =====\n",
      "with\t-4.3458\n",
      "donald\t-4.5146\n",
      "...\t-4.7004\n",
      "gop\t-4.7279\n",
      "i\t-4.9475\n",
      "on\t-4.9608\n",
      "he\t-4.9925\n",
      "…\t-5.1155\n",
      "https\t-5.1699\n",
      "what\t-5.1699\n",
      "===== group 3 =====\n",
      "bernie\t-1.5945\n",
      "sanders\t-1.6609\n",
      "hillary\t-2.2188\n",
      "and\t-2.5154\n",
      "\"\t-2.5930\n",
      "in\t-2.6114\n",
      "will\t-2.6160\n",
      "https\t-2.6674\n",
      "...\t-2.7004\n",
      "you\t-2.7004\n",
      "===== group 4 =====\n",
      "what\t-3.4330\n",
      "have\t-3.4725\n",
      "bernie\t-3.5380\n",
      "this\t-3.5518\n",
      "it\t-3.6881\n",
      "?\t-3.6912\n",
      "for\t-3.7110\n",
      "about\t-3.7415\n",
      "hillary\t-3.7549\n",
      "that\t-3.7625\n",
      "===== group 5 =====\n",
      "what\t-1.8007\n",
      "not\t-1.8745\n",
      "https\t-2.0000\n",
      "his\t-2.0144\n",
      "cruz\t-2.0704\n",
      "it\t-2.1031\n",
      "on\t-2.1243\n",
      "&\t-2.1399\n",
      "amp\t-2.1489\n",
      ";\t-2.1592\n",
      "===== group 6 =====\n",
      "will\t-1.3847\n",
      "have\t-1.4725\n",
      "!\t-1.5850\n",
      "cruz\t-1.6919\n",
      "trump\t-1.7199\n",
      "https\t-1.7549\n",
      "-\t-1.7673\n",
      ";\t-1.7807\n",
      "be\t-1.7952\n",
      "amp\t-1.8144\n",
      "===== group 7 =====\n",
      "donald\t-1.0740\n",
      "trump\t-1.6535\n",
      "bernie\t-1.7790\n",
      "sanders\t-1.7829\n",
      "’\t-1.8613\n",
      "of\t-1.9069\n",
      "?\t-1.9186\n",
      "with\t-1.9307\n",
      "the\t-1.9588\n",
      "be\t-1.9758\n"
     ]
    }
   ],
   "source": [
    "save_time(\"print popular tokens in each group\")\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# Create RDD mapping each (partition k, token t) to each user_id.\n",
    "# Eliminate duplicates (a user may use several times the same token, has to be counted ONE use at most)\n",
    "rdd_tok_by_users_and_group = rdd_by_partition.flatMap(lambda x: [(x[0], t, x[1][0]) for t in tok.tokenize(x[1][1])]).distinct()\n",
    "rdd_tok_by_users_and_group = rdd_tok_by_users_and_group.map(lambda x: ((x[1], x[0]), x[2]))\n",
    "\n",
    "# Create RDD counting the number of unique user_id, within each group, who mention each token.\n",
    "rdd_tok_by_user_and_group_count = rdd_tok_by_users_and_group.groupByKey().map(lambda x: (x[0], len([i for i in x[1]])))\n",
    "rdd_tok_by_user_and_group_count = rdd_tok_by_user_and_group_count.map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "\n",
    "# Join rdd_tok_by_user_and_group_count and rdd_tok_by_user_count_filt based on token t\n",
    "rdd_join_by_tok = rdd_tok_by_user_and_group_count.join(rdd_tok_by_user_count_filt)\n",
    "rdd_join_by_tok = rdd_join_by_tok.map(lambda x: (x[0], (x[1][0][0], x[1][0][1], x[1][1])))\n",
    "\n",
    "# Compute relative popularity (p) and sort by (-p, t)\n",
    "rdd_rel_pop = rdd_join_by_tok.map(lambda x: ((x[1][0], (x[0], get_rel_popularity(x[1][1],x[1][2]))))).sortBy(lambda x: (-x[1][1], x[1][0]))\n",
    "\n",
    "# Filter top 10 relative popularity in each group\n",
    "#rdd_rel_pop_top10 = rdd_rel_pop.groupByKey().map(lambda x : (list(x[1])[:10]))\n",
    "#popular_10_in_each_group = rdd_rel_pop_top10.collect()\n",
    "\n",
    "rdd_rel_pop_top10 = rdd_rel_pop.groupByKey().map(lambda x : (list(x[1])))\n",
    "popular_10_in_each_group = rdd_rel_pop_top10.collect()\n",
    "\n",
    "correction = []\n",
    "for group in popular_10_in_each_group:\n",
    "    correction.append(sorted(group, key=lambda x: (-x[1], x[0]))[:10])\n",
    "    \n",
    "popular_10_in_each_group = correction\n",
    "\n",
    "my_output.append(\"popular_10_in_each_group\", popular_10_in_each_group)\n",
    "for k in range(8):\n",
    "    print_tokens(popular_10_in_each_group[k], k)\n",
    "save_time(\"print popular tokens in each group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Important: Write your solutions to disk\n",
    "\n",
    "Following cell write your solutions to disk which would be read in by the grader for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:12:16.421484Z",
     "start_time": "2023-02-12T15:12:16.382078Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "my_output.write_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Runtime statistics of your implementation\n",
    "\n",
    "When you run locally, the runtime of your implementation printed here will **NOT** be an accurate reflection of how your implementation will run on clusters. The time it takes to run locally might be faster or slower than running on clusters depending on the resources of your device (if you develop on your own device) or the workload of the workbench (if you develop on Vocareum).\n",
    "\n",
    "If you want a relatively accurate estimate, please submit and see the runtime printed in the grading report. Note that the time estimated here in the grading report only considers the time it takes to run your application. There will be an inevitable overhead in grading to submit the Spark application and collect the logs, which will be included in the total runtime that will be used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T15:12:16.465280Z",
     "start_time": "2023-02-12T15:12:16.428420Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 0:00:11\n",
      "set up sc 0:00:02\n",
      "read data 0:00:02\n",
      "count unique users 0:00:00\n",
      "count tweets per user partition 0:00:02\n",
      "count all unique tokens 0:00:01\n",
      "count overall most popular tokens 0:00:01\n",
      "print popular tokens in each group 0:00:02\n"
     ]
    }
   ],
   "source": [
    "save_time('total time')\n",
    "\n",
    "for key in timer:\n",
    "    print(key, timer[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 343.181818,
   "position": {
    "height": "40px",
    "left": "1245.44px",
    "right": "20px",
    "top": "122.997px",
    "width": "457px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
