{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa1806c15bc34f91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Boosting and Random Forests\n",
    "\n",
    "In this programming assignment, your task is to classify geographical locations according to their predicted tree cover using Gradient Boosting and Random Forest classifiers. You are expected to fill in functions that would complete this task. All of the necessary helper code is included in this notebook. However, we advise you to go over the slides, lecture material and the corresponding notebooks before you attempt this Programming Assignment. You can find information about the dataset to be used in the following links:\n",
    "\n",
    "* **Dataset:** http://archive.ics.uci.edu/ml/datasets/Covertype \n",
    "\n",
    "* **Dataset description:** http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa1806c15c34f91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# To time the entire solution\n",
    "import time\n",
    "start_nb = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a77b283c3c040501",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-22486e239350>:7 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-22486e239350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    294\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 296\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-22486e239350>:7 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3dc492f41da1397e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import pickle\n",
    "from os.path import exists, join\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e66236b3e86ecf9f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Cover Types: {1.0: 'Spruce/Fir', 2.0: 'Lodgepole Pine', 3.0: 'Ponderosa Pine', 4.0: 'Cottonwood/Willow', 5.0: 'Aspen', 6.0: 'Douglas-fir', 7.0: 'Krummholz'}\n"
     ]
    }
   ],
   "source": [
    "#define a dictionary of cover types\n",
    "CoverTypes={1.0: 'Spruce/Fir',\n",
    "            2.0: 'Lodgepole Pine',\n",
    "            3.0: 'Ponderosa Pine',\n",
    "            4.0: 'Cottonwood/Willow',\n",
    "            5.0: 'Aspen',\n",
    "            6.0: 'Douglas-fir',\n",
    "            7.0: 'Krummholz' }\n",
    "print('Tree Cover Types:', CoverTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-601dbde74a330c36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee2d7617e6961570",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Break up features that are made out of several binary features.\n",
    "def get_columns(cols_txt):\n",
    "    cols=[a.strip() for a in cols_txt.split(',')]\n",
    "    colDict={a:[a] for a in cols}\n",
    "    colDict['Soil_Type (40 binary columns)'] = ['ST_'+str(i) for i in range(40)]\n",
    "    colDict['Wilderness_Area (4 binarycolumns)'] = ['WA_'+str(i) for i in range(4)]\n",
    "    columns=[]\n",
    "    for item in cols:\n",
    "        columns = columns + colDict[item]\n",
    "    return columns\n",
    "    #print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63c74c999a27b45f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the feature names\n",
    "cols_txt=\"\"\"\n",
    "Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n",
    "Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n",
    "Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n",
    "Horizontal_Distance_To_Fire_Points, Wilderness_Area (4 binarycolumns), \n",
    "Soil_Type (40 binary columns), Cover_Type\n",
    "\"\"\"\n",
    "columns = get_columns(cols_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-39425dea9979acb3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Read the file into an RDD\n",
    "# When using sc.textRead you need to use an absolute path.\n",
    "# If doing this on a real cluster, you need the file to be available on all nodes, ideally in HDFS.\n",
    "path='covtype/covtype.data'\n",
    "inputRDD=sc.textFile(join('./resource/asnlib/publicdata', path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6329e83b6ee7fd32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Helper Functions\n",
    "Here are some helper functions that you will have to fill up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfb574e5ebeb330c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### label_RDD\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Finish `label_RDD` function. The function takes an RDD as input and returns an RDD of labeled points.\n",
    "\n",
    "\n",
    "Input: \n",
    "\n",
    "- `inputRDD`: RDD consisting of a string with comma separated values\n",
    "\n",
    "Output: \n",
    "\n",
    "- RDD of the type [`LabeledPoint`](https://spark.apache.org/docs/2.2.1/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) with the first element being the label and second element being a DenseVector that contains all the elements of the InputRDD(Except the last value which is the label).\n",
    "\n",
    "---\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "'2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5'\n",
    "```\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def label_RDD(inputRDD):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    Data = inputRDD.map(lambda x: tuple([float(x[-1]), [float(i) for i in x[:-2].split(',')]]))\n",
    "    Data = Data.map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7ffe45353a6d5ad",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[474] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = label_RDD(inputRDD)\n",
    "Data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "labelRDD",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert Data.first().label == 5.0\n",
    "assert Data.first().features == Vectors.dense([2596.0, 51.0, 3.0, 258.0, 0.0, 510.0, 221.0, 232.0, 148.0, 6279.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27a14578d81eed8c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### count_examples\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Finish `count_examples` function. The function takes an RDD as input and returns count of number of labels belonging to each class.\n",
    "\n",
    "Input: \n",
    "\n",
    "- `Data`: RDD obtained as the output of the labelRDD\n",
    "\n",
    "Output: \n",
    "\n",
    "- list of tuples (label, count)\n",
    "\n",
    "**NOTE: The outputs need to be sorted in descending order by counts.**\n",
    "\n",
    "---\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "[LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    " LabeledPoint(5.0, [2590.0,56.0,2.0,212.0,-6.0,390.0,220.0,235.0,151.0,6225.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    " LabeledPoint(2.0, [2804.0,139.0,9.0,268.0,65.0,3180.0,234.0,238.0,135.0,6121.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]\n",
    "```\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "[(5.0, 2), (2.0, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad446944695ea686",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def count_examples(Data):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    counts_by_label = Data.map(lambda x: (x.label, x.features)).countByKey()\n",
    "    counts_by_label = [(k, counts_by_label[k]) for k in counts_by_label]\n",
    "    counts_by_label.sort(key=lambda x: x[1], reverse=True)\n",
    "    return counts_by_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a678d8b03134f4bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "counts = count_examples(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.0, 283301), (1.0, 211840), (3.0, 35754), (7.0, 20510), (6.0, 17367), (5.0, 9493), (4.0, 2747)]\n"
     ]
    }
   ],
   "source": [
    "# Check & tests\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a585400e9d239e42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "counts3 = count_examples(sc.parallelize(Data.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.0, 2), (2.0, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Check & tests\n",
    "print(counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_tc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(counts3) == list, 'Incorrect return type'\n",
    "assert type(counts3[0]) == tuple, 'Incorrect return type'\n",
    "assert type(counts3[0][0]) == float, 'Incorrect return type'\n",
    "assert type(counts3[0][1]) == int, 'Incorrect return type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_vc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert counts3[0][0] == 5.0, 'Incorrect return value'\n",
    "assert counts3[0][1] == 2, 'Incorrect return value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_vch",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-019033d0bb8c2c73",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size= 581012\n",
      "              type (label):   percent of total\n",
      "---------------------------------------------------------\n",
      "      Lodgepole Pine (2.0):\t48.76\n",
      "          Spruce/Fir (1.0):\t36.46\n",
      "      Ponderosa Pine (3.0):\t6.15\n",
      "           Krummholz (7.0):\t3.53\n",
      "         Douglas-fir (6.0):\t2.99\n",
      "               Aspen (5.0):\t1.63\n",
      "   Cottonwood/Willow (4.0):\t0.47\n"
     ]
    }
   ],
   "source": [
    "total=Data.count()\n",
    "print('total data size=',total)\n",
    "print('              type (label):   percent of total')\n",
    "print('---------------------------------------------------------')\n",
    "print('\\n'.join(['%20s (%3.1f):\\t%4.2f'%(CoverTypes[a[0]],a[0],100.0*a[1]/float(total)) for a in counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8fcdc59eb2f4e08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### labels_to_binary (Making the problem binary)\n",
    "\n",
    "The implementation of BoostedGradientTrees in MLLib supports only binary problems. the `CovType` problem has\n",
    "7 classes. To make the problem binary we choose the `Lodgepole Pine` (label = 2.0). We therefore transform the dataset to a new dataset where the label is `1.0` is the class is `Lodgepole Pine` and is `0.0` otherwise.\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Finish `labels_to_binary` function. The function takes an RDD as input and returns an RDD with binary labels such that: \n",
    "\n",
    "```python\n",
    "if label == 2:      # Since label 2 has the highest count value\n",
    "    new_label = 1\n",
    "    \n",
    "else:\n",
    "    new_label = 0\n",
    "```\n",
    "\n",
    "Input: \n",
    "\n",
    "- `Data`: Labelled RDD (Output from `label_RDD` function)\n",
    "\n",
    "Output: \n",
    "\n",
    "- The same RDD with label of all entries as 0 except for label = 2.0 where label becomes 1.0\n",
    "\n",
    "---\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "LabeledPoint(0.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68e335dc015340e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def labels_to_binary(Data):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    \n",
    "    return Data.map(lambda x: LabeledPoint(1.0, x.features) if x.label==2.0 else LabeledPoint(0.0, x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0099fa01e48236a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Data = labels_to_binary(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "L2B_vc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Data.first().label == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eee681d192a47b23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reducing data size\n",
    "For this assignment, we will use only 10% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7daae8ed96a71326",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trainingData = sc.parallelize(pickle.load(open(join('./resource/asnlib/publicdata', 'training10p.pkl'), 'rb')))\n",
    "testData = sc.parallelize(pickle.load(open(join('./resource/asnlib/publicdata', 'test10p.pkl'), 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d12b5d6c39a98a8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: Data1=58100, trainingData=40682, testData=17418\n"
     ]
    }
   ],
   "source": [
    "print('Sizes: Data1=%d, trainingData=%d, testData=%d'%(trainingData.cache().count() + testData.cache().count(),trainingData.cache().count(),testData.cache().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d06ade87c62cad8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "counts = count_examples(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Training classifiers\n",
    "\n",
    "We will train classifiers using Gradient Boosted Trees and Random Forest implemented in pyspark.mllib package and evaluate their performances. \n",
    "\n",
    "You can follow the [example here](http://spark.apache.org/docs/2.2.1/mllib-ensembles.html#classification) from the mllib documentation if you don't know how to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7476b6ae9251c7dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Gradient Boosted Trees\n",
    "\n",
    "Pyspark has a built-in implementation of Gradient Boosted Trees. Please see [`trainClassifier`](http://spark.apache.org/docs/2.2.1/api/python/pyspark.mllib.html#pyspark.mllib.tree.GradientBoostedTrees) on how to train it on a dataset and [`predict`](https://spark.apache.org/docs/2.2.1/api/python/pyspark.mllib.html#pyspark.mllib.tree.GradientBoostedTreesModel.predict) on how to predict the labels for a dataset.\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Finish `Classify_GB` function. The function trains a GradientBoostedTrees classifier that has trees with a maximum depth of `maxDepth` on the training data for 10 iterations and returns the error on the test data.\n",
    "\n",
    "Input: \n",
    "\n",
    "- `trainingData` (RDD): Training data\n",
    "- `testData` (RDD): Test data\n",
    "- `maxDepth` (int): Depth of tree\n",
    "\n",
    "Output:\n",
    "\n",
    "- error (float)\n",
    "\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "- Use `categoricalFeaturesInfo={}` for `trainClassifier`.\n",
    "- Use default parameters for `trainClassifier` unless specified otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9bdfd4c81113b03",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def Classify_GB(trainingData, testData, maxDepth):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    model = GradientBoostedTrees.trainClassifier(trainingData, categoricalFeaturesInfo={}, numIterations=10, maxDepth=maxDepth)\n",
    "    \n",
    "    predictions = model.predict(testData.map(lambda x: x.features))\n",
    "    \n",
    "    labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "\n",
    "    testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "    \n",
    "    return testErr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_1_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "visible_results=pickle.load(open(join('./resource/asnlib/publicdata', 'GradientBoostingResultsVisible.pkl'),'rb'))\n",
    "assert Classify_GB(trainingData, testData, 1) <= visible_results['B_10p_1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_3_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Classify_GB(trainingData, testData, 3) <= visible_results['B_10p_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_6_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_10_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Random Forests\n",
    "\n",
    "Pyspark has a built-in implementation of Random Forests. Please see [`trainClassifier`](http://spark.apache.org/docs/2.2.1/api/python/pyspark.mllib.html#pyspark.mllib.tree.RandomForest) on how to train it on a dataset and [`predict`](https://spark.apache.org/docs/2.2.1/api/python/pyspark.mllib.html#pyspark.mllib.tree.RandomForestModel.predict) on how to predict the labels for a dataset.\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Finish `Classify_RF` function. The function trains a RandomForest classifier that has 10 trees with a maximum depth of `maxDepth` on the training data and returns the error on the test data.\n",
    "\n",
    "Input\n",
    "\n",
    "- `trainingData` (RDD): Training data\n",
    "- `testData` (RDD): Test data\n",
    "- `maxDepth` (int): Depth of tree\n",
    "\n",
    "Output: \n",
    "\n",
    "- error (float)\n",
    "\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "- Don't forget to manually set `numClasses` for `trainClassifier`.\n",
    "- Use `categoricalFeaturesInfo={}` for `trainClassifier`.\n",
    "- Use default parameters for `trainClassifier` unless specified otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1772af5d3c6c0273",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def Classify_RF(trainingData, testData, maxDepth):    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    model = RandomForest.trainClassifier(trainingData, categoricalFeaturesInfo={}, numClasses=2, numTrees=10, maxDepth=maxDepth)\n",
    "    \n",
    "    predictions = model.predict(testData.map(lambda x: x.features))\n",
    "    \n",
    "    labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "\n",
    "    testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "    \n",
    "    return testErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_3_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "visible_results_rf=pickle.load(open(join('./resource/asnlib/publicdata', 'RandomForestResultsVisible.pkl'),'rb'))\n",
    "assert Classify_RF(trainingData, testData, 3) <= visible_results_rf['RF_10p_3'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_6_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Classify_RF(trainingData, testData, 6) <= visible_results_rf['RF_10p_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_8_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_10_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  45.518805742263794\n"
     ]
    }
   ],
   "source": [
    "end_nb = time.time()\n",
    "print(\"Total time taken: \", end_nb - start_nb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": [],
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
